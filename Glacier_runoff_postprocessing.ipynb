{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943e8556-1d13-4f33-ae0d-f6ea4eacc75f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Glacier evolution postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874009b-3f05-44a0-839e-4fc8b31c7e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import geopandas as gpd\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "variables = [\"melt_off_glacier_daily\", \"melt_on_glacier_daily\", \"liq_prcp_off_glacier_daily\", \"liq_prcp_on_glacier_daily\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846121b6-37a8-463d-842a-332a3962a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions\n",
    "def julian_to_gregorian(year, julian_day):\n",
    "\n",
    "    year = int(year)\n",
    "    julian_day = int(julian_day)\n",
    "    gregorian_date = pd.to_datetime(f'{int(year)}-01-01')\n",
    "    gregorian_date += pd.to_timedelta(julian_day - 1, unit='D')\n",
    "    gregorian_date = np.array(gregorian_date, dtype='datetime64[ns]')\n",
    "    return gregorian_date\n",
    "\n",
    "def change_calendar(ds):\n",
    "\n",
    "    ds = ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month', 'calendar_day_2d'])\n",
    "    ds = ds.stack(datetime=(\"time\", \"day_2d\"))\n",
    "    dates = [julian_to_gregorian(year, day) for year, day in ds.datetime.values]\n",
    "    ds = ds.drop_vars([\"datetime\", 'time', 'day_2d'])\n",
    "    ds[\"datetime\"] = dates\n",
    "    ds = ds.dropna(\"datetime\", how = \"all\")\n",
    "    return ds\n",
    "\n",
    "def hydro_variables(ds): # calculate total_runoff\n",
    "    ds[\"glacier_runoff\"] = ((ds.melt_off_glacier_daily + ds.melt_on_glacier_daily + ds.liq_prcp_off_glacier_daily + ds.liq_prcp_on_glacier_daily)*1e-3)/(86400) # m3/s\n",
    "    return ds[\"glacier_runoff\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c931f55d-d2bf-4fa6-afdb-ec774e1ea5d1",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cea48e-b004-4177-879d-5de385ea4345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "path_raw   = \"/home/rooda/Hydro_results/oggm_runs_daily/\"\n",
    "path_final = \"/home/rooda/OneDrive/DeepHydro/\"\n",
    "path_pmet  = \"/home/rooda/OneDrive/PatagoniaMet/\"\n",
    "\n",
    "# glacier dataset\n",
    "RGI_ids    = gpd.read_file(path_final + \"GIS/Glaciers/RGI7_Hydro.shp\")\n",
    "\n",
    "# catchment dataset\n",
    "q_metadata   = pd.read_csv(path_pmet + \"Zenodo/v11/Q_PMETobs_v11_metadata.csv\", index_col = \"gauge_id\")\n",
    "q_metadata[\"gauge_code\"] = q_metadata[\"gauge_code\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829bbd4-1b50-40b4-949d-c615c05897a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Historical period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f96887-ac64-4282-a56c-f143e405ded0",
   "metadata": {},
   "source": [
    "### Glacier runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef21c30-02f6-4546-9330-832feb55f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all patagonian catchments\n",
    "oggm_ts  = xr.open_dataset(path_raw + \"run_output_historical.nc\")[variables]\n",
    "oggm_ts  = oggm_ts.sel(time = slice(1990,2019)) # 2020 with no data\n",
    "oggm_ts  = change_calendar(oggm_ts)\n",
    "oggm_ts  = hydro_variables(oggm_ts)\n",
    "oggm_ts  = oggm_ts.assign_coords(rgi_id = RGI_ids.ID_basin.tolist())\n",
    "oggm_ts  = oggm_ts.groupby('rgi_id').sum()\n",
    "oggm_ts  = oggm_ts.to_dataframe().reset_index().rename(columns = {\"datetime\": \"time\"})\n",
    "oggm_ts  = oggm_ts.pivot(index = \"time\", columns = \"rgi_id\", values = \"total_runoff\")\n",
    "oggm_ts  = oggm_ts.round(3) # save some space\n",
    "oggm_ts.to_csv(path_final + \"Runoff/glacier_runoff_historical_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40e533-8476-4e8a-baf9-a5695abfe797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for PMET-obs catchments (calibration)\n",
    "oggm_ts  = xr.open_dataset(path_raw + \"run_output_historical.nc\")[variables]\n",
    "oggm_ts  = oggm_ts.sel(time = slice(1980,2019)) # 2020 with no data\n",
    "oggm_ts  = change_calendar(oggm_ts)\n",
    "oggm_ts  = hydro_variables(oggm_ts)\n",
    "\n",
    "oggm_ts_ds = pd.DataFrame(columns = q_metadata.index, index = oggm_ts.datetime.values)\n",
    "for basin in tqdm(q_metadata.index):\n",
    "\n",
    "    # candidates\n",
    "    id_candidates = (q_metadata['gauge_code'].str.startswith(q_metadata['gauge_code'].loc[basin]) & \n",
    "                   (q_metadata['gauge_code'].str.len() >= len(q_metadata['gauge_code'].loc[basin])))\n",
    "    id_candidates = q_metadata['gauge_code'][id_candidates]\n",
    "    \n",
    "    if np.sum(RGI_ids['ID_PMET'].isin(id_candidates)) > 0:\n",
    "\n",
    "        rgi_candidates = RGI_ids[RGI_ids.ID_PMET.isin(id_candidates)].RGIId\n",
    "        oggm_ts_basin = oggm_ts.sel(rgi_id = rgi_candidates.to_list())\n",
    "        oggm_ts_basin = oggm_ts_basin.sum(dim = \"rgi_id\").to_series()\n",
    "        oggm_ts_ds[basin] = oggm_ts_basin\n",
    "\n",
    "oggm_ts_ds = oggm_ts_ds.fillna(0).round(3) \n",
    "oggm_ts_ds.index.name = \"time\"\n",
    "oggm_ts_ds.to_csv(path_final + \"Runoff/glacier_runoff_historical_pmet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd201272-28e4-4694-a971-1fb221cd48bc",
   "metadata": {},
   "source": [
    "### Glacier melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34ccc5-bafb-491f-88d8-cb6479e8b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all patagonian catchments\n",
    "oggm_ts  = xr.open_dataset(path_raw + \"run_output_historical.nc\")[variables]\n",
    "oggm_ts  = oggm_ts.sel(time = slice(1990,2019)) # 2020 with no data\n",
    "oggm_ts  = change_calendar(oggm_ts)[\"melt_on_glacier_daily\"]\n",
    "oggm_ts  = oggm_ts*1e-3/86400\n",
    "oggm_ts  = oggm_ts.assign_coords(rgi_id = RGI_ids.ID_basin.tolist())\n",
    "oggm_ts  = oggm_ts.groupby('rgi_id').sum()\n",
    "oggm_ts  = oggm_ts.to_dataframe().reset_index().rename(columns = {\"datetime\": \"time\"})\n",
    "oggm_ts  = oggm_ts.pivot(index = \"time\", columns = \"rgi_id\", values = \"melt_on_glacier_daily\")\n",
    "oggm_ts  = oggm_ts.round(3) # save some space\n",
    "oggm_ts.to_csv(path_final + \"Runoff/glacier_melt_historical_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0206615-a86a-4519-8d12-25070a4edfdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for PMET-obs catchments (calibration)\n",
    "oggm_ts  = xr.open_dataset(path_raw + \"run_output_historical.nc\")[variables]\n",
    "oggm_ts  = oggm_ts.sel(time = slice(1980,2019)) # 2020 with no data\n",
    "oggm_ts  = change_calendar(oggm_ts)[\"melt_on_glacier_daily\"]\n",
    "oggm_ts  = oggm_ts*1e-3/86400\n",
    "\n",
    "oggm_ts_ds = pd.DataFrame(columns = q_metadata.index, index = oggm_ts.datetime.values)\n",
    "for basin in tqdm(q_metadata.index):\n",
    "\n",
    "    # candidates\n",
    "    id_candidates = (q_metadata['gauge_code'].str.startswith(q_metadata['gauge_code'].loc[basin]) & \n",
    "                   (q_metadata['gauge_code'].str.len() >= len(q_metadata['gauge_code'].loc[basin])))\n",
    "    id_candidates = q_metadata['gauge_code'][id_candidates]\n",
    "    \n",
    "    if np.sum(RGI_ids['ID_PMET'].isin(id_candidates)) > 0:\n",
    "\n",
    "        rgi_candidates = RGI_ids[RGI_ids.ID_PMET.isin(id_candidates)].RGIId\n",
    "        oggm_ts_basin = oggm_ts.sel(rgi_id = rgi_candidates.to_list())\n",
    "        oggm_ts_basin = oggm_ts_basin.sum(dim = \"rgi_id\").to_series()\n",
    "        oggm_ts_ds[basin] = oggm_ts_basin\n",
    "\n",
    "oggm_ts_ds = oggm_ts_ds.fillna(0).round(3) \n",
    "oggm_ts_ds.index.name = \"time\"\n",
    "oggm_ts_ds.to_csv(path_final + \"Runoff/glacier_melt_historical_pmet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431bdbce-9264-47f9-84fd-23d2ba82ec71",
   "metadata": {},
   "source": [
    "### Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7fe63a-54b6-4d41-a1a7-6b670499439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all patagonian catchments\n",
    "oggm_ts  = xr.open_dataset(path_raw + \"run_output_historical.nc\").volume\n",
    "oggm_ts = oggm_ts.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])\n",
    "oggm_ts  = oggm_ts.assign_coords(rgi_id = RGI_ids.ID_basin.tolist())\n",
    "oggm_ts  = oggm_ts.groupby('rgi_id').sum()\n",
    "oggm_ts  = oggm_ts.to_dataframe().reset_index().rename(columns = {\"datetime\": \"time\"})\n",
    "oggm_ts  = oggm_ts.pivot(index = \"time\", columns = \"rgi_id\", values = \"volume\")\n",
    "oggm_ts  = oggm_ts.round(3) # save some space\n",
    "oggm_ts.to_csv(path_final + \"Runoff/glacier_volume_historical_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e5787a-df4a-4208-98a6-469f9d685f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for PMET-obs catchments (calibration)\n",
    "oggm_ts  = xr.open_dataset(path_raw + \"run_output_historical.nc\").volume\n",
    "oggm_ts = oggm_ts.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])\n",
    "\n",
    "oggm_ts_ds = pd.DataFrame(columns = q_metadata.index, index = oggm_ts.time.values)\n",
    "for basin in tqdm(q_metadata.index):\n",
    "\n",
    "    # candidates\n",
    "    id_candidates = (q_metadata['gauge_code'].str.startswith(q_metadata['gauge_code'].loc[basin]) & \n",
    "                   (q_metadata['gauge_code'].str.len() >= len(q_metadata['gauge_code'].loc[basin])))\n",
    "    id_candidates = q_metadata['gauge_code'][id_candidates]\n",
    "    \n",
    "    if np.sum(RGI_ids['ID_PMET'].isin(id_candidates)) > 0:\n",
    "\n",
    "        rgi_candidates = RGI_ids[RGI_ids.ID_PMET.isin(id_candidates)].RGIId\n",
    "        oggm_ts_basin = oggm_ts.sel(rgi_id = rgi_candidates.to_list())\n",
    "        oggm_ts_basin = oggm_ts_basin.sum(dim = \"rgi_id\").to_series()\n",
    "        oggm_ts_ds[basin] = oggm_ts_basin\n",
    "\n",
    "oggm_ts_ds = oggm_ts_ds.fillna(0).round(3) \n",
    "oggm_ts_ds.index.name = \"time\"\n",
    "oggm_ts_ds.to_csv(path_final + \"Runoff/glacier_volume_historical_pmet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b684cfd-788d-4b2f-872f-2e81756961d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Future period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab7193-2c34-411a-9e63-091f10dbd576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcm_list  = [\"GFDL-ESM4\", \"IPSL-CM6A-LR\", \"MIROC6\", \"MPI-ESM1-2-LR\", \"MRI-ESM2-0\"]\n",
    "ssp_list  = [\"ssp126\", \"ssp585\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a8169-adf4-4425-8b89-93056ce26b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glacier runoff (daily)\n",
    "\n",
    "df_ssp = []\n",
    "for ssp in tqdm(ssp_list):\n",
    "    \n",
    "    df_gcm = []\n",
    "    for gcm in tqdm(gcm_list, leave = False): \n",
    "        oggm_ts  = xr.open_mfdataset(path_raw + \"run_output_{}_{}*.nc\".format(gcm,ssp), combine='nested', concat_dim= \"rgi_id\")[variables].load()\n",
    "        oggm_ts  = change_calendar(oggm_ts)\n",
    "        oggm_ts  = hydro_variables(oggm_ts)\n",
    "        oggm_ts  = oggm_ts.sortby(\"rgi_id\").assign_coords(rgi_id = RGI_ids.ID_basin.tolist())\n",
    "        oggm_ts  = oggm_ts.groupby('rgi_id').sum()\n",
    "        df_gcm.append(oggm_ts)\n",
    "    \n",
    "    df_gcm = xr.concat(df_gcm, dim='gcm')\n",
    "    df_ssp.append(df_gcm)\n",
    "\n",
    "df_ssp = xr.concat(df_ssp, dim='ssp')\n",
    "df_ssp = df_ssp.assign_coords(gcm=gcm_list, ssp=ssp_list)\n",
    "df_ssp = df_ssp.rename({'datetime': 'time'})\n",
    "df_ssp = df_ssp.sel(time = slice(\"2020-01-01\",\"2099-12-31\")) \n",
    "df_ssp = df_ssp.astype(\"float32\")\n",
    "df_ssp.to_netcdf(path_final + \"Runoff/glacier_runoff_future_all.nc\", \n",
    "                 encoding = {'glacier_runoff': {'dtype': 'int32', 'scale_factor': 0.001, '_FillValue': -9999, 'zlib': True, 'complevel': 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea976a83-bb93-46e6-b2d7-b99d62f0d38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Glacier melt (in m3/s)\n",
    "\n",
    "df_ssp = []\n",
    "for ssp in tqdm(ssp_list):\n",
    "    \n",
    "    df_gcm = []\n",
    "    for gcm in tqdm(gcm_list, leave = False): \n",
    "        oggm_ts  = xr.open_mfdataset(path_raw + \"run_output_{}_{}*.nc\".format(gcm,ssp), combine='nested', concat_dim= \"rgi_id\").melt_on_glacier_daily.load()\n",
    "        oggm_ts  = change_calendar(oggm_ts)\n",
    "        oggm_ts  = oggm_ts*1e-3/86400\n",
    "        oggm_ts  = oggm_ts.sortby(\"rgi_id\").assign_coords(rgi_id = RGI_ids.ID_basin.tolist())\n",
    "        oggm_ts  = oggm_ts.groupby('rgi_id').sum()\n",
    "        df_gcm.append(oggm_ts)\n",
    "    \n",
    "    df_gcm = xr.concat(df_gcm, dim='gcm')\n",
    "    df_ssp.append(df_gcm)\n",
    "\n",
    "df_ssp = xr.concat(df_ssp, dim='ssp')\n",
    "df_ssp = df_ssp.assign_coords(gcm=gcm_list, ssp=ssp_list)\n",
    "df_ssp = df_ssp.rename({'datetime': 'time'})\n",
    "df_ssp = df_ssp.sel(time = slice(\"2020-01-01\",\"2099-12-31\")) \n",
    "df_ssp = df_ssp.astype(\"float32\")\n",
    "df_ssp.to_netcdf(path_final + \"Runoff/glacier_melt_future_all.nc\", \n",
    "                 encoding = {'melt_on_glacier_daily': {'dtype': 'int32', 'scale_factor': 0.001, '_FillValue': -9999, 'zlib': True, 'complevel': 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85695039-5945-4433-84c9-82f77d1677ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Glacier volume (in m3)\n",
    "\n",
    "df_ssp = []\n",
    "for ssp in tqdm(ssp_list):\n",
    "    \n",
    "    df_gcm = []\n",
    "    for gcm in tqdm(gcm_list, leave = False): \n",
    "        oggm_ts  = xr.open_mfdataset(path_raw + \"run_output_{}_{}*.nc\".format(gcm,ssp), combine='nested', concat_dim= \"rgi_id\")[\"volume\"]\n",
    "        oggm_ts  = oggm_ts.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month']).load()\n",
    "        oggm_ts  = oggm_ts.sortby(\"rgi_id\").assign_coords(rgi_id = RGI_ids.ID_basin.tolist())\n",
    "        oggm_ts  = oggm_ts.groupby('rgi_id').sum()\n",
    "        df_gcm.append(oggm_ts)\n",
    "    \n",
    "    df_gcm = xr.concat(df_gcm, dim='gcm')\n",
    "    df_ssp.append(df_gcm)\n",
    "\n",
    "df_ssp = xr.concat(df_ssp, dim='ssp')\n",
    "df_ssp = df_ssp.assign_coords(gcm=gcm_list, ssp=ssp_list)\n",
    "df_ssp = df_ssp.astype(\"int64\")\n",
    "df_ssp.to_netcdf(path_final + \"Runoff/glacier_volume_future_all.nc\", \n",
    "                 encoding = {\"volume\": {'dtype': 'int64', 'zlib': True, 'complevel': 1}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
